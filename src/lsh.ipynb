{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 11:16:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext, StorageLevel\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkFiles\n",
    "import re\n",
    "import random\n",
    "\n",
    "\n",
    "path = \"../data/covid_news_truncated.json\"\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.getAll()\n",
    "\n",
    "sc = SparkContext(appName=\"lsh\")\n",
    "    \n",
    "spark = SparkSession(sc)\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "textfile = sc.textFile(path)\n",
    "\n",
    "#sc.addFile(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 15, 4, 0, 2, 1, 5, 2, 1, 0, 2, 1, 2, 1, 3, 2, 2, 13, 0, 1, 6, 4, 0, 5, 4, 0, 2, 5, 0, 2, 1, 0, 0, 0, 9, 5, 9, 0, 0, 4, 0, 0, 5, 7, 1, 3, 1, 1, 0, 3, 0, 1, 2, 1, 1, 12, 0, 1, 1, 5, 3, 8, 0, 4, 1, 2, 0, 16, 8, 2, 3, 0, 4, 8, 1, 1, 4, 5, 5, 8, 7, 3, 9, 5, 1, 1, 20, 1, 0, 0, 8, 2, 2, 0, 0, 2, 3, 0, 5, 3, 1, 1, 3, 1, 6, 1, 2, 2, 2, 1, 5, 1, 0, 2, 1, 0, 3, 2, 6, 0, 0, 0, 2, 0, 1, 1, 2, 0, 4, 2, 2, 0, 0, 0, 13, 4, 6, 2, 0, 1, 2, 6, 5]\n",
      "[5, 2, 1, 1, 0, 2, 1, 1, 5, 8, 0, 1, 0, 1, 0, 2, 0, 0, 1, 5, 2, 1, 0, 1, 3, 1, 1, 1, 1, 5, 1, 0, 1, 0, 2, 0, 3, 6, 7, 0, 5, 0, 0, 8, 9, 3, 2, 0, 0, 0, 12, 5, 0, 1, 3, 1, 4, 3, 6, 1, 1, 4, 3, 0, 0, 2, 1, 8, 0, 3, 9, 1, 0, 9, 2, 0, 0, 3, 1, 0, 0, 4, 0, 0, 0, 5, 1, 3, 4, 3, 0, 0, 4, 1, 0, 4, 5, 0, 5, 6, 0, 0, 1, 0, 0, 6, 1, 2, 0, 5, 3, 0, 2, 16, 0, 8, 7, 11, 1, 3, 4, 2, 2, 10, 2, 2, 1, 4, 4, 6, 2, 0, 2, 2, 6, 3, 0, 4, 11, 0, 9, 0, 1]\n",
      "[0, 15, 4, 0, 2, 1, 5, 2, 1, 0, 2, 1, 2, 1, 3, 2, 2, 13, 0, 1, 6, 4, 0, 5, 4, 0, 2, 5, 0, 2, 1, 0, 0, 0, 9, 5, 9, 0, 0, 4, 0, 0, 5, 7, 1, 3, 1, 1, 0, 3, 0, 1, 2, 1, 1, 12, 0, 1, 1, 5, 3, 8, 0, 4, 1, 2, 0, 16, 8, 2, 3, 0, 4, 8, 1, 1, 4, 5, 5, 8, 7, 3, 9, 5, 1, 1, 20, 1, 0, 0, 8, 2, 2, 0, 0, 2, 3, 0, 5, 3, 1, 1, 3, 1, 6, 1, 2, 2, 2, 1, 5, 1, 0, 2, 1, 0, 3, 2, 6, 0, 0, 0, 2, 0, 1, 1, 2, 0, 4, 2, 2, 0, 0, 0, 13, 4, 6, 2, 0, 1, 2, 6, 5]\n",
      "[5, 2, 1, 1, 0, 2, 1, 1, 5, 8, 0, 1, 0, 1, 0, 2, 0, 0, 1, 5, 2, 1, 0, 1, 3, 1, 1, 1, 1, 5, 1, 0, 1, 0, 2, 0, 3, 6, 7, 0, 5, 0, 0, 8, 9, 3, 2, 0, 0, 0, 12, 5, 0, 1, 3, 1, 4, 3, 6, 1, 1, 4, 3, 0, 0, 2, 1, 8, 0, 3, 9, 1, 0, 9, 2, 0, 0, 3, 1, 0, 0, 4, 0, 0, 0, 5, 1, 3, 4, 3, 0, 0, 4, 1, 0, 4, 5, 0, 5, 6, 0, 0, 1, 0, 0, 6, 1, 2, 0, 5, 3, 0, 2, 16, 0, 8, 7, 11, 1, 3, 4, 2, 2, 10, 2, 2, 1, 4, 4, 6, 2, 0, 2, 2, 6, 3, 0, 4, 11, 0, 9, 0, 1]\n",
      "[0, 15, 4, 0, 2, 1, 5, 2, 1, 0, 2, 1, 2, 1, 3, 2, 2, 13, 0, 1, 6, 4, 0, 5, 4, 0, 2, 5, 0, 2, 1, 0, 0, 0, 9, 5, 9, 0, 0, 4, 0, 0, 5, 7, 1, 3, 1, 1, 0, 3, 0, 1, 2, 1, 1, 12, 0, 1, 1, 5, 3, 8, 0, 4, 1, 2, 0, 16, 8, 2, 3, 0, 4, 8, 1, 1, 4, 5, 5, 8, 7, 3, 9, 5, 1, 1, 20, 1, 0, 0, 8, 2, 2, 0, 0, 2, 3, 0, 5, 3, 1, 1, 3, 1, 6, 1, 2, 2, 2, 1, 5, 1, 0, 2, 1, 0, 3, 2, 6, 0, 0, 0, 2, 0, 1, 1, 2, 0, 4, 2, 2, 0, 0, 0, 13, 4, 6, 2, 0, 1, 2, 6, 5]\n",
      "[0, 15, 4, 0, 2, 1, 5, 2, 1, 0, 2, 1, 2, 1, 3, 2, 2, 13, 0, 1, 6, 4, 0, 5, 4, 0, 2, 5, 0, 2, 1, 0, 0, 0, 9, 5, 9, 0, 0, 4, 0, 0, 5, 7, 1, 3, 1, 1, 0, 3, 0, 1, 2, 1, 1, 12, 0, 1, 1, 5, 3, 8, 0, 4, 1, 2, 0, 16, 8, 2, 3, 0, 4, 8, 1, 1, 4, 5, 5, 8, 7, 3, 9, 5, 1, 1, 20, 1, 0, 0, 8, 2, 2, 0, 0, 2, 3, 0, 5, 3, 1, 1, 3, 1, 6, 1, 2, 2, 2, 1, 5, 1, 0, 2, 1, 0, 3, 2, 6, 0, 0, 0, 2, 0, 1, 1, 2, 0, 4, 2, 2, 0, 0, 0, 13, 4, 6, 2, 0, 1, 2, 6, 5]\n",
      "('3', '2', 1.0)\n",
      "('2', '1', 0.07518796992481203)\n",
      "('3', '1', 0.07518796992481203)\n"
     ]
    }
   ],
   "source": [
    "# Large prime value to use in hashing\n",
    "LARGE_PRIME = 75874811\n",
    "\n",
    "# number of hash functions\n",
    "R_VALUE = 13\n",
    "B_VALUE = 11\n",
    "K_VALUE = R_VALUE * B_VALUE\n",
    "\n",
    "# generate random array to use in hashing\n",
    "RANDOM_ARRAY = [(random.randint(1,2**31 - 1), random.randint(1,2**31 - 1)) for i in range(0,K_VALUE)]\n",
    "#print((421*value + 16) % 1013)\n",
    "\n",
    "\n",
    "\n",
    "# gets document and returns k-shingles\n",
    "def shingles(document, k=9):\n",
    "\n",
    "    #initial set\n",
    "    shingles_set = set()\n",
    "\n",
    "    # getting rid of punctuation, etc\n",
    "    document[1] = re.sub(r'[^\\w\\s]', '', document[1].lower())\n",
    "\n",
    "    # split to chars\n",
    "    chars_list = re.split('', document[1].lower())\n",
    "\n",
    "    # create shingles with length k\n",
    "    for i in range(len(chars_list) - k):\n",
    "        chars = chars_list[i:i + k]\n",
    "        shingle = ''.join(chars)\n",
    "        shingles_set.add(shingle)\n",
    "\n",
    "    # sort shingles\n",
    "    shingles_set = sorted(shingles_set)\n",
    "\n",
    "    # returns: doc_id, set_shingles\n",
    "    return document[0], shingles_set\n",
    "\n",
    "\n",
    "# hash a value\n",
    "def hash_function(x, a, b, N): \n",
    "    return (((a * hash(x) + b) % LARGE_PRIME ) % N)\n",
    "\n",
    "# get signature matrix from min hashing\n",
    "def min_hash(document, total_size):\n",
    "    \n",
    "    # shingles\n",
    "    x = document[1]\n",
    "\n",
    "    # initial matrix\n",
    "    signature_matrix = []\n",
    "\n",
    "    # iterate through the defined number of hash functions (hi)\n",
    "    for i in range(0, K_VALUE):\n",
    "\n",
    "        # start value is infinite\n",
    "        minhash = float('inf')\n",
    "\n",
    "        # get random integers\n",
    "        a,b = RANDOM_ARRAY[i]\n",
    "\n",
    "        # for each shingle\n",
    "        for value in x:\n",
    "            # hash shingle\n",
    "            h = hash_function(value,a,b, len(x))\n",
    "            # if lower, replace with current value\n",
    "            if h < minhash:\n",
    "                minhash = h\n",
    "\n",
    "        # append the lowest number\n",
    "        signature_matrix.append(minhash)\n",
    "\n",
    "    #print(signature_matrix)\n",
    "    \n",
    "    # returns: doc_id, signature matrix\n",
    "    return document[0],signature_matrix\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------- #\n",
    "\n",
    "# gets a band and hashes it to a bucket\n",
    "def hash_lsh(band): \n",
    "\n",
    "    # intial array\n",
    "    h1_array = []\n",
    "\n",
    "    # for each row within the band\n",
    "    for value in band:\n",
    "        # hash\n",
    "        h1_array.append((value * len(band)) % LARGE_PRIME)\n",
    "\n",
    "    #returns: min value\n",
    "    return min(h1_array)\n",
    "\n",
    "# gets signature and returns bucket values for each band\n",
    "def get_bucket_values(signature):\n",
    "\n",
    "    # list of bucket values\n",
    "    bucket_values = []\n",
    "\n",
    "    # for the entire signature, iterate over each band with r rows and hash it\n",
    "    for idx in range(0, B_VALUE):\n",
    "\n",
    "        # if there is no more bands to hash\n",
    "        if idx * R_VALUE > len(signature): \n",
    "            break \n",
    "\n",
    "        # get end of band\n",
    "        max_id = min(idx * R_VALUE + R_VALUE, len(signature))\n",
    "\n",
    "        # hash the band to a bucket\n",
    "        bucket = hash_lsh(signature[idx * R_VALUE : max_id])\n",
    "\n",
    "        # append bucket value\n",
    "        bucket_values.append(bucket)\n",
    "\n",
    "    # returns: doc_id, bucket values\n",
    "    return bucket_values\n",
    "\n",
    "# given the signatures, returns candidate pairs\n",
    "def lsh_algorithm(signatures_matrix):\n",
    "\n",
    "    # dict with buckets for each document\n",
    "    k_buckets = {}\n",
    "\n",
    "    # initial candidates list\n",
    "    candidates = []\n",
    "\n",
    "    # iterate over the signatures\n",
    "    for doc in signatures_matrix:\n",
    "\n",
    "        # get the bucket values for each signature\n",
    "        bucket = get_bucket_values(signatures_matrix[doc])\n",
    "\n",
    "        # iterate over the other signatures bucket values\n",
    "        for b_doc in k_buckets:\n",
    "\n",
    "            # iterate over the bucket values\n",
    "            for i in range(len(bucket)):\n",
    "\n",
    "                # if at least 1 bucket value is the same, then at least 1 band hashes to the same bucket -> candidate \n",
    "                if k_buckets[b_doc][i] == bucket[i]:\n",
    "\n",
    "                    # because it is candidate, compare with jaccard similarity and append to candidates list\n",
    "                    similar_pair = jaccard_similarity(signatures_matrix[doc], signatures_matrix[b_doc])\n",
    "                    candidates.append((doc, b_doc, similar_pair))\n",
    "\n",
    "                    # because we only need 1 hash value in the same bucket, no need to continue\n",
    "                    break\n",
    "\n",
    "        # add the bucket values for each signature\n",
    "        k_buckets[doc] = bucket\n",
    "\n",
    "    # returns: candidates\n",
    "    return candidates\n",
    "\n",
    "# calculate jaccard similarity\n",
    "def jaccard_similarity(sig_matrix_1, sig_matrix_2):\n",
    "    print(sig_matrix_1)\n",
    "    print(sig_matrix_2)\n",
    "    # get intersection of the 2 matrices\n",
    "    intersection = len([sig_matrix_1[i] for i in range(0, len(sig_matrix_1)) if (sig_matrix_1[i] == sig_matrix_2[i])])\n",
    "    # get union of the 2 matrices\n",
    "    union = (len(sig_matrix_1) + len(sig_matrix_2)) - intersection\n",
    "    # calculate jaccard similarity\n",
    "    jaccard_sim = intersection / union\n",
    "\n",
    "    return jaccard_sim\n",
    "\n",
    "\n",
    "def shingles_jaccard(shingles_1, shingles_2):\n",
    "    intersection = len(list(set(shingles_1).intersection(shingles_2)))\n",
    "    union = (len(set(shingles_1)) + len(set(shingles_2))) - intersection\n",
    "    return float(intersection) / union\n",
    "\n",
    "\n",
    "def article_shingles_similarity(doc_id, lsh_candidates, filtered_shingles):\n",
    "    for x in filtered_shingles:\n",
    "        if x[0] == str(doc_id):\n",
    "            doc_shingles = x[1]\n",
    "\n",
    "    print(doc_id)\n",
    "    print(doc_shingles)\n",
    "\n",
    "    for candidate in filtered_shingles:\n",
    "        if str(doc_id) != candidate[0]:\n",
    "            jacc = shingles_jaccard(doc_shingles, candidate[1])\n",
    "            print(str(doc_id) + \" jaccard sim with \" + candidate[0] + \": \" + str(jacc))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "final_shingles = textfile.map(lambda line: eval(line)) \\\n",
    "                .map(lambda dict: [dict[\"tweet_id\"], dict[\"text\"]]) \\\n",
    "                .map(shingles)\n",
    "\n",
    "total_size = final_shingles.count()\n",
    "final_minhash = final_shingles.map(lambda k: min_hash(k, total_size))\n",
    "\n",
    "#print(\"shingles and minhash done\")\n",
    "\n",
    "signatures_matrix = { doc: sig_matrix for doc, sig_matrix in final_minhash.collect() }\n",
    "#\n",
    "#print(\"collect done\")\n",
    "#\n",
    "#print(signatures_matrix)\n",
    "\n",
    "candidates = lsh_algorithm(signatures_matrix)\n",
    "#\n",
    "#print(\"similar pairs found\")\n",
    "#\n",
    "sorted_candidates = sc.parallelize(candidates).sortBy(lambda pair: - pair[2])\n",
    "#\n",
    "#print(\"final pairs done\")\n",
    "#\n",
    "final_results = sorted_candidates.collect()\n",
    "#\n",
    "#for x in final_results[:10]:\n",
    "    #print(x[0])\n",
    "    #print(type(x[0]))\n",
    "\n",
    "    #if x[0] == 1349048668570189824:\n",
    "    #    print(\"entrou\")\n",
    "    #print(x)\n",
    "\n",
    "for x in final_results[:10]:\n",
    "    print(x)\n",
    "\n",
    "\n",
    "#article = 1349045380101648384\n",
    "#filtered_candidates = sorted_candidates.filter(lambda x: x[0] == str(article)).collect()\n",
    "#print(filtered_candidates)\n",
    "#\n",
    "#candidates_ids = [filtered_candidates[0][0]] + [x[1] for x in filtered_candidates]\n",
    "##print(candidates_ids)\n",
    "#\n",
    "#filtered_shingles = final_shingles.filter(lambda x: x[0] in candidates_ids).collect()\n",
    "#\n",
    "#article_shingles_similarity(article, filtered_candidates, filtered_shingles)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
